{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Titanic\n",
    "\n",
    "[Titanic on Kaggle](https://www.kaggle.com/c/titanic/overview)\n",
    "\n",
    "Predict survival on the Titanic and get familiar with ML basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will help us to measure the time it took for the whole\n",
    "# notebook to execute\n",
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "import os\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('../../utils')\n",
    "import datasets\n",
    "importlib.reload(datasets)\n",
    "import helpers\n",
    "importlib.reload(helpers)\n",
    "\n",
    "# Allows plot inside jupyer notebooks\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import sklearn\n",
    "from sklearn.pipeline import Pipeline               # Allows you to create a sequence of transformations and a final estimator in a single, cohesive workflow\n",
    "from sklearn.impute import SimpleImputer            # Used to fill in missing values in your dataset.\n",
    "from sklearn.preprocessing import StandardScaler    # Standardizes features by removing the mean and scaling them to unit variance\n",
    "from sklearn.preprocessing import OneHotEncoder     # Used to encode categorical variables as one-hot (or dummy) variables.\n",
    "from sklearn.compose import ColumnTransformer       # Allows you to apply different transformations to different columns within a DataFrame\n",
    "from sklearn.ensemble import RandomForestClassifier # Builds an ensemble of decision trees, averaging their predictions to reduce overfitting.\n",
    "from sklearn.model_selection import cross_val_score # Provides robust model evaluation by using multiple train-test splits, leading to a more accurate estimate of model performance.\n",
    "from sklearn.svm import SVC                         # A powerful classification algorithm that uses hyperplanes to separate classes, particularly effective in high-dimensional spaces or with complex class boundaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITANIC_PATH = os.path.join(\"../../datasets\", \"titanic\")\n",
    "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\"\n",
    "DATASET_FILES = [\"train.csv\", \"test.csv\"]\n",
    "\n",
    "datasets.download(DOWNLOAD_URL, TITANIC_PATH, DATASET_FILES)\n",
    "train_data = datasets.load_csv(TITANIC_PATH, DATASET_FILES[0])\n",
    "test_data = datasets.load_csv(TITANIC_PATH, DATASET_FILES[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset preview\n",
    "\n",
    "The attributes have the following meaning:\n",
    "\n",
    "| Attribute | Meaning | Key |\n",
    "|:---|:---|:---|\n",
    "| PassengerId | Unique identifier | |\n",
    "| Survived | Indicates if passenger survived | 0 = No, 1 = Yes |\n",
    "| Pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n",
    "| Name | Name of the passanger | |\n",
    "| Sex | Sex of the passanger | |\n",
    "| Age | Age in years | |\n",
    "| SibSp | # of siblings / spouses aboard the Titanic | |\n",
    "| Parch | # of parents / children aboard the Titanic | |\n",
    "| Ticket | Ticket number | |\n",
    "| Fare | Passenger fare | |\n",
    "| Cabin | Cabin number | |\n",
    "| Embarked | Port of embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set \"PassengerId\" as the index column\n",
    "train_data = train_data.set_index(\"PassengerId\")\n",
    "test_data = test_data.set_index(\"PassengerId\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review data and see if anything is missing\n",
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the median age of females passengers\n",
    "train_data[train_data[\"Sex\"]==\"female\"][\"Age\"].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical attributes\n",
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Validate more data\n",
    "\n",
    "Validate some other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Survived\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Pclass\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Sex\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Embarked\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing pipeline\n",
    "\n",
    "Preprocessing pipeline that takes the raw data and outputs numerical input features that we can feed to any Machine Learning model we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline for numerical attributes\n",
    "num_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "# Pipeline for categorical attributes\n",
    "cat_pipeline = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"cat_encoder\", OneHotEncoder(sparse_output=False)),\n",
    "    ])\n",
    "\n",
    "# Join pipelines\n",
    "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "preprocess_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, num_attribs),\n",
    "        (\"cat\", cat_pipeline, cat_attribs),\n",
    "    ])\n",
    "\n",
    "# Adding labels\n",
    "y_train = train_data[\"Survived\"]\n",
    "\n",
    "# Preview\n",
    "X_train = preprocess_pipeline.fit_transform(\n",
    "    train_data[num_attribs + cat_attribs])\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "forest_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "forest_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "X_test = preprocess_pipeline.transform(test_data[num_attribs + cat_attribs])\n",
    "y_pred = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validate the model\n",
    "forest_scores = cross_val_score(forest_clf, X_train, y_train, cv=10)\n",
    "forest_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try with an SVC\n",
    "svm_clf = SVC(gamma=\"auto\")\n",
    "svm_scores = cross_val_score(svm_clf, X_train, y_train, cv=10)\n",
    "svm_scores.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot models\n",
    "\n",
    "The random forest classifier got a very high score on one of the 10 folds, but overall it had a lower mean score, as well as a bigger spread, so it looks like the SVM classifier is more likely to generalize well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot([1]*10, svm_scores, \".\")\n",
    "plt.plot([2]*10, forest_scores, \".\")\n",
    "plt.boxplot([svm_scores, forest_scores], tick_labels=(\"SVM\",\"Random Forest\"))\n",
    "plt.ylabel(\"Accuracy\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Total Time\n",
    "\n",
    "This show the total time of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the total time of execution\n",
    "end_time = time.time()\n",
    "helpers.calculate_execution_time(start_time, end_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maestria-sandbox-M6nm_6C6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
