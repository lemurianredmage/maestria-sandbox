{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificator\n",
    "\n",
    "PoC for tattoo verificator.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import os\n",
    "import csv\n",
    "import hashlib\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models, transforms\n",
    "from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and common methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = Path(\"../datasets/tattoos\")\n",
    "bound_box_path = Path(f\"{base_path}/bounding_boxes\")\n",
    "images_path = Path(f\"{base_path}/images\")\n",
    "\n",
    "image_index_csv = f\"{base_path}/image_index.csv\"\n",
    "duplicates_file = f\"{base_path}/duplicates.txt\"\n",
    "corrupt_files_file = f\"{base_path}/corrupt_files.txt\"\n",
    "\n",
    "resized_images_folder = f\"{base_path}/resized_color\"\n",
    "processed_images_folder = f\"{base_path}/processed_images_grayscale\"\n",
    "image_index_with_labels_csv = f\"{base_path}/image_index_with_labels.csv\"\n",
    "\n",
    "dataset_split_folder = f\"{base_path}/dataset_split\"\n",
    "train_csv = f\"{dataset_split_folder}/train.csv\"\n",
    "val_csv = f\"{dataset_split_folder}/val.csv\"\n",
    "test_csv = f\"{dataset_split_folder}/test.csv\"\n",
    "\n",
    "def remove_single_file(file_path):\n",
    "    try:\n",
    "        os.remove(file_path)\n",
    "    except OSError:\n",
    "        pass\n",
    "\n",
    "def remove_folder(folder_path):\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    else:\n",
    "        shutil.rmtree(folder_path)\n",
    "        os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base images in data folder: \n",
      "     Total of bounding boxes:  4411\n",
      "     Total of images:  4411\n",
      "     Total of base images:  161\n",
      "\n",
      "Base images and their variants\n",
      "    Base image '118_1.JPG' has 21 variants.\n",
      "    Base image '103_2.JPG' has 21 variants.\n",
      "    Base image '77_1.JPG' has 21 variants.\n",
      "    Base image '32_1.JPG' has 21 variants.\n",
      "    Base image '14_2.JPG' has 21 variants.\n",
      "    Base image '53_1.JPG' has 21 variants.\n",
      "    Base image '16_1.JPG' has 21 variants.\n",
      "    Base image '144_1.JPG' has 21 variants.\n",
      "    Base image '93_1.JPG' has 21 variants.\n",
      "    Base image '91_1.JPG' has 21 variants.\n",
      "    Base image '146_1.JPG' has 21 variants.\n",
      "    Base image '103_1.JPG' has 21 variants.\n",
      "    Base image '51_1.JPG' has 21 variants.\n",
      "    Base image '14_1.JPG' has 21 variants.\n",
      "    Base image '88_1.JPG' has 21 variants.\n",
      "    Base image '75_1.JPG' has 21 variants.\n",
      "    Base image '16_2.JPG' has 21 variants.\n",
      "    Base image '127_1.JPG' has 21 variants.\n",
      "    Base image '48_1.JPG' has 21 variants.\n",
      "    Base image '10_4.JPG' has 21 variants.\n",
      "    Base image '71_1.JPG' has 21 variants.\n",
      "    Base image '34_1.JPG' has 21 variants.\n",
      "    Base image '12_2.JPG' has 21 variants.\n",
      "    Base image '123_1.JPG' has 21 variants.\n",
      "    Base image '68_1.JPG' has 21 variants.\n",
      "    Base image '95_1.JPG' has 21 variants.\n",
      "    Base image '12_3.JPG' has 21 variants.\n",
      "    Base image '10_1.JPG' has 21 variants.\n",
      "    Base image '10_3.JPG' has 21 variants.\n",
      "    Base image '12_1.JPG' has 21 variants.\n",
      "    Base image '34_2.JPG' has 21 variants.\n",
      "    Base image '105_1.JPG' has 21 variants.\n",
      "    Base image '97_1.JPG' has 21 variants.\n",
      "    Base image '138_1.JPG' has 21 variants.\n",
      "    Base image '159_1.JPG' has 21 variants.\n",
      "    Base image '121_1.JPG' has 21 variants.\n",
      "    Base image '73_1.JPG' has 21 variants.\n",
      "    Base image '36_1.JPG' has 21 variants.\n",
      "    Base image '10_2.JPG' has 21 variants.\n",
      "    Base image '17_3.JPG' has 21 variants.\n",
      "    Base image '102_1.JPG' has 21 variants.\n",
      "    Base image '9_3.JPG' has 21 variants.\n",
      "    Base image '147_1.JPG' has 21 variants.\n",
      "    Base image '15_1.JPG' has 21 variants.\n",
      "    Base image '50_1.JPG' has 21 variants.\n",
      "    Base image '90_1.JPG' has 21 variants.\n",
      "    Base image '11_5.JPG' has 21 variants.\n",
      "    Base image '49_1.JPG' has 21 variants.\n",
      "    Base image '11_4.JPG' has 21 variants.\n",
      "    Base image '89_1.JPG' has 21 variants.\n",
      "    Base image '31_1.JPG' has 21 variants.\n",
      "    Base image '74_1.JPG' has 21 variants.\n",
      "    Base image '17_2.JPG' has 21 variants.\n",
      "    Base image '126_1.JPG' has 21 variants.\n",
      "    Base image '124_1.JPG' has 21 variants.\n",
      "    Base image '33_1.JPG' has 21 variants.\n",
      "    Base image '76_1.JPG' has 21 variants.\n",
      "    Base image '15_2.JPG' has 21 variants.\n",
      "    Base image '119_1.JPG' has 21 variants.\n",
      "    Base image '11_6.JPG' has 21 variants.\n",
      "    Base image '92_1.JPG' has 21 variants.\n",
      "    Base image '15_3.JPG' has 21 variants.\n",
      "    Base image '9_1.JPG' has 21 variants.\n",
      "    Base image '17_1.JPG' has 42 variants.\n",
      "    Base image '52_1.JPG' has 21 variants.\n",
      "    Base image '145_1.JPG' has 21 variants.\n",
      "    Base image '17_5.JPG' has 21 variants.\n",
      "    Base image '9_5.JPG' has 21 variants.\n",
      "    Base image '96_1.JPG' has 21 variants.\n",
      "    Base image '13_1.JPG' has 21 variants.\n",
      "    Base image '56_1.JPG' has 21 variants.\n",
      "    Base image '104_1.JPG' has 21 variants.\n",
      "    Base image '11_3.JPG' has 21 variants.\n",
      "    Base image '120_1.JPG' has 21 variants.\n",
      "    Base image '37_1.JPG' has 21 variants.\n",
      "    Base image '11_2.JPG' has 21 variants.\n",
      "    Base image '9_4.JPG' has 21 variants.\n",
      "    Base image '158_1.JPG' has 21 variants.\n",
      "    Base image '17_4.JPG' has 21 variants.\n",
      "    Base image '17_6.JPG' has 21 variants.\n",
      "    Base image '15_4.JPG' has 21 variants.\n",
      "    Base image '35_1.JPG' has 21 variants.\n",
      "    Base image '70_1.JPG' has 21 variants.\n",
      "    Base image '13_2.JPG' has 21 variants.\n",
      "    Base image '122_1.JPG' has 21 variants.\n",
      "    Base image '11_1.JPG' has 21 variants.\n",
      "    Base image '54_1.JPG' has 21 variants.\n",
      "    Base image '37_2.JPG' has 21 variants.\n",
      "    Base image '15_5.JPG' has 21 variants.\n",
      "    Base image '69_1.JPG' has 21 variants.\n",
      "    Base image '17_7.JPG' has 21 variants.\n",
      "    Base image '65_1.JPG' has 21 variants.\n",
      "    Base image '20_1.JPG' has 21 variants.\n",
      "    Base image '137_1.JPG' has 21 variants.\n",
      "    Base image '98_1.JPG' has 21 variants.\n",
      "    Base image '58_1.JPG' has 21 variants.\n",
      "    Base image '39_1.JPG' has 21 variants.\n",
      "    Base image '81_1.JPG' has 21 variants.\n",
      "    Base image '1_2.JPG' has 21 variants.\n",
      "    Base image '156_1.JPG' has 21 variants.\n",
      "    Base image '113_1.JPG' has 21 variants.\n",
      "    Base image '22_2.JPG' has 21 variants.\n",
      "    Base image '41_1.JPG' has 21 variants.\n",
      "    Base image '17_9.JPG' has 21 variants.\n",
      "    Base image '20_2.JPG' has 21 variants.\n",
      "    Base image '43_1.JPG' has 21 variants.\n",
      "    Base image '154_1.JPG' has 21 variants.\n",
      "    Base image '111_1.JPG' has 21 variants.\n",
      "    Base image '83_1.JPG' has 21 variants.\n",
      "    Base image '1_1.JPG' has 21 variants.\n",
      "    Base image '135_1.JPG' has 21 variants.\n",
      "    Base image '22_1.JPG' has 21 variants.\n",
      "    Base image '17_8.JPG' has 21 variants.\n",
      "    Base image '24_2.JPG' has 21 variants.\n",
      "    Base image '47_1.JPG' has 21 variants.\n",
      "    Base image '115_1.JPG' has 21 variants.\n",
      "    Base image '19_2.JPG' has 21 variants.\n",
      "    Base image '128_1.JPG' has 21 variants.\n",
      "    Base image '87_1.JPG' has 21 variants.\n",
      "    Base image '85_1.JPG' has 21 variants.\n",
      "    Base image '78_1.JPG' has 21 variants.\n",
      "    Base image '152_1.JPG' has 21 variants.\n",
      "    Base image '117_1.JPG' has 21 variants.\n",
      "    Base image '45_1.JPG' has 21 variants.\n",
      "    Base image '61_1.JPG' has 21 variants.\n",
      "    Base image '24_1.JPG' has 21 variants.\n",
      "    Base image '19_1.JPG' has 21 variants.\n",
      "    Base image '82_1.JPG' has 21 variants.\n",
      "    Base image '21_2.JPG' has 21 variants.\n",
      "    Base image '110_1.JPG' has 21 variants.\n",
      "    Base image '155_1.JPG' has 21 variants.\n",
      "    Base image '134_1.JPG' has 21 variants.\n",
      "    Base image '66_1.JPG' has 21 variants.\n",
      "    Base image '21_3.JPG' has 21 variants.\n",
      "    Base image '80_2.JPG' has 21 variants.\n",
      "    Base image '2_1.JPG' has 21 variants.\n",
      "    Base image '21_1.JPG' has 21 variants.\n",
      "    Base image '64_1.JPG' has 21 variants.\n",
      "    Base image '136_1.JPG' has 21 variants.\n",
      "    Base image '99_1.JPG' has 21 variants.\n",
      "    Base image '112_1.JPG' has 21 variants.\n",
      "    Base image '157_1.JPG' has 21 variants.\n",
      "    Base image '40_1.JPG' has 21 variants.\n",
      "    Base image '38_1.JPG' has 21 variants.\n",
      "    Base image '80_1.JPG' has 21 variants.\n",
      "    Base image '116_1.JPG' has 21 variants.\n",
      "    Base image '153_1.JPG' has 21 variants.\n",
      "    Base image '17_10.JPG' has 21 variants.\n",
      "    Base image '44_1.JPG' has 21 variants.\n",
      "    Base image '84_1.JPG' has 21 variants.\n",
      "    Base image '21_4.JPG' has 21 variants.\n",
      "    Base image '79_1.JPG' has 21 variants.\n",
      "    Base image '6_1.JPG' has 21 variants.\n",
      "    Base image '132_1.JPG' has 21 variants.\n",
      "    Base image '130_1.JPG' has 21 variants.\n",
      "    Base image '148_1.JPG' has 21 variants.\n",
      "    Base image '4_1.JPG' has 21 variants.\n",
      "    Base image '129_1.JPG' has 21 variants.\n",
      "    Base image '86_1.JPG' has 21 variants.\n",
      "    Base image '114_1.JPG' has 21 variants.\n",
      "    Base image '151_1.JPG' has 21 variants.\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^\\d+_\\d+\\.JPG'\n",
    "total_bound_boxes = [file.name for file in bound_box_path.iterdir() if file.is_file()]\n",
    "all_images = [file.name for file in images_path.iterdir() if file.is_file()]\n",
    "base_images = [file.name for file in images_path.iterdir() if file.is_file() and re.match(pattern, file.name)]\n",
    "\n",
    "print (\"Base images in data folder: \")\n",
    "print(\"     Total of bounding boxes: \", len(total_bound_boxes))\n",
    "print(\"     Total of images: \", len(all_images))\n",
    "print(\"     Total of base images: \", len(base_images))\n",
    "print('')\n",
    "print(\"Base images and their variants\")\n",
    "\n",
    "base_image_variant_counts = {base_image: 0 for base_image in base_images}\n",
    "\n",
    "for image in all_images:\n",
    "    for base_image in base_images:\n",
    "        if image.startswith(base_image[:-4]):\n",
    "            base_image_variant_counts[base_image] += 1\n",
    "\n",
    "for base_image, count in base_image_variant_counts.items():\n",
    "    print(f\"    Base image '{base_image}' has {count} variants.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Index\n",
    "\n",
    "file_path | label | transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV Index file created at: ../datasets/tattoos/image_index.csv\n"
     ]
    }
   ],
   "source": [
    "remove_single_file(image_index_csv)\n",
    "\n",
    "with open(image_index_csv, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"file_path\", \"label\", \"transformation\"])\n",
    "    \n",
    "    for filename in os.listdir(images_path):\n",
    "        if filename.endswith(('.jpg', '.jpeg', '.png', 'JPG', '.PNG', '.JPEG')):\n",
    "            parts = filename.split(\"_\")\n",
    "            label = parts[0]\n",
    "            transformation = parts[-1].split(\".\")[0] if len(parts) > 2 else \"original\"\n",
    "            file_path = os.path.join(images_path, filename)\n",
    "            writer.writerow([file_path, label, transformation])\n",
    "\n",
    "print(f\"CSV Index file created at: {image_index_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check\n",
    "\n",
    "Check for corrupted images or duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates found: 5 (details on ../datasets/tattoos/duplicates.txt)\n",
      "Corrupted files found: 0 (details on ../datasets/tattoos/corrupt_files.txt)\n"
     ]
    }
   ],
   "source": [
    "remove_single_file(duplicates_file)\n",
    "remove_single_file(corrupt_files_file)\n",
    "\n",
    "# Detect duplicates\n",
    "hashes = {}\n",
    "duplicates = []\n",
    "\n",
    "# Corrupted files\n",
    "corrupt_files = []\n",
    "\n",
    "for filename in os.listdir(images_path):\n",
    "    file_path = os.path.join(images_path, filename)\n",
    "    try:\n",
    "        # Check for corrupted data\n",
    "        with Image.open(file_path) as img:\n",
    "            img.verify()\n",
    "        \n",
    "        # Check hash\n",
    "        with open(file_path, \"rb\") as f:\n",
    "            file_hash = hashlib.md5(f.read()).hexdigest()\n",
    "        \n",
    "        # Check for duplicates\n",
    "        if file_hash in hashes:\n",
    "            duplicates.append((file_path, hashes[file_hash]))\n",
    "        else:\n",
    "            hashes[file_hash] = file_path\n",
    "    except Exception as e:\n",
    "        # Save corrupted file\n",
    "        corrupt_files.append(file_path)\n",
    "\n",
    "# Save duplicates\n",
    "with open(duplicates_file, \"w\") as f:\n",
    "    for dup, original in duplicates:\n",
    "        f.write(f\"{dup} is duplicate of {original}\\n\")\n",
    "\n",
    "# Save corrupted\n",
    "with open(corrupt_files_file, \"w\") as f:\n",
    "    for corrupt in corrupt_files:\n",
    "        f.write(f\"{corrupt} is corrupted\\n\")\n",
    "\n",
    "print(f\"Duplicates found: {len(duplicates)} (details on {duplicates_file})\")\n",
    "print(f\"Corrupted files found: {len(corrupt_files)} (details on {corrupt_files_file})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resized images found at: ../datasets/tattoos/resized_color\n"
     ]
    }
   ],
   "source": [
    "remove_folder(resized_images_folder)\n",
    "\n",
    "for filename in os.listdir(images_path):\n",
    "    img = cv2.imread(os.path.join(images_path, filename))\n",
    "    resized_img = cv2.resize(img, (224, 224))\n",
    "    cv2.imwrite(os.path.join(resized_images_folder, filename), resized_img)\n",
    "\n",
    "print(f\"Resized images found at: {resized_images_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalization and consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed images found at: ../datasets/tattoos/processed_images_grayscale\n"
     ]
    }
   ],
   "source": [
    "remove_folder(processed_images_folder)\n",
    "\n",
    "# Processing parameters\n",
    "target_size = (224, 224)  # Fixed size\n",
    "normalize_range = (0, 1)  # Range [0, 1] o [-1, 1]\n",
    "color_mode = \"grayscale\"  # Options: \"rgb\" o \"grayscale\"\n",
    "\n",
    "def normalize_image(image, range_min, range_max):\n",
    "    image = image.astype(\"float32\")  # Convertir a flotante\n",
    "    if range_min == 0 and range_max == 1:\n",
    "        return image / 255.0  # Normalizar a [0, 1]\n",
    "    elif range_min == -1 and range_max == 1:\n",
    "        return (image / 127.5) - 1.0  # Normalizar a [-1, 1]\n",
    "    else:\n",
    "        raise ValueError(\"Invalid normalization range.\")\n",
    "\n",
    "# Image processing\n",
    "for filename in os.listdir(images_path):\n",
    "    input_path = os.path.join(images_path, filename)\n",
    "    output_path = os.path.join(processed_images_folder, filename)\n",
    "\n",
    "    # Read image\n",
    "    image = cv2.imread(input_path)\n",
    "    if image is None:\n",
    "        print(f\"Warning: could not load image {input_path}. Skipped.\")\n",
    "        continue\n",
    "\n",
    "    # Format conversion\n",
    "    if color_mode == \"rgb\":\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    elif color_mode == \"grayscale\":\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid color mode. Choose either 'rgb' or 'grayscale'.\")\n",
    "\n",
    "    # Resize\n",
    "    image = cv2.resize(image, target_size)\n",
    "\n",
    "    # Pixel normalization\n",
    "    normalized_image = normalize_image(image, *normalize_range)\n",
    "\n",
    "    # Save processed images\n",
    "    if color_mode == \"grayscale\":\n",
    "        cv2.imwrite(output_path, (normalized_image * 255).astype(\"uint8\"))\n",
    "    else:\n",
    "        cv2.imwrite(output_path, (normalized_image * 255).astype(\"uint8\")[:, :, ::-1])  # Convert RGB to BGR to save\n",
    "\n",
    "print(f\"Processed images found at: {processed_images_folder}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV with additional labels at: ../datasets/tattoos/image_index_with_labels.csv\n"
     ]
    }
   ],
   "source": [
    "remove_single_file(image_index_with_labels_csv)\n",
    "\n",
    "difficulty_mapping = {\n",
    "    \"original\": \"easy\",\n",
    "    \"a1\": \"medium\", \"a2\": \"medium\", \"a3\": \"medium\", \"a4\": \"medium\",\n",
    "    \"ar1\": \"medium\", \"ar2\": \"medium\", \"ar3\": \"medium\", \"ar4\": \"medium\",\n",
    "    \"b1\": \"hard\", \"b2\": \"hard\",\n",
    "    \"c1\": \"medium\", \"c2\": \"medium\", \"c3\": \"medium\", \"c4\": \"medium\",\n",
    "    \"i1\": \"medium\", \"i2\": \"medium\",\n",
    "    \"r1\": \"hard\", \"r2\": \"hard\", \"r3\": \"hard\", \"r4\": \"hard\"\n",
    "}\n",
    "\n",
    "image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.PNG', '*.JPEG']\n",
    "\n",
    "original_image_paths = []\n",
    "for ext in image_extensions:\n",
    "    original_image_paths.extend(glob.glob(os.path.join(processed_images_folder, ext)))\n",
    "\n",
    "csv_data = []\n",
    "\n",
    "def extract_info_from_filename(filename):\n",
    "    basename = os.path.basename(filename)\n",
    "    parts = basename.split(\"_\")\n",
    "    \n",
    "    label = parts[0]\n",
    "    number = parts[1]\n",
    "    transformation = parts[2].replace(\".jpg\", \"\").replace(\".jpeg\", \"\").replace(\".png\", \"\").replace(\".JPG\", \"\").replace(\".PNG\", \"\").replace(\".JPEG\", \"\") if len(parts) > 2 else \"original\"    \n",
    "    return label, number, transformation\n",
    "\n",
    "for image_path in original_image_paths:\n",
    "    label, number, transformation = extract_info_from_filename(image_path)\n",
    "    \n",
    "    difficulty = difficulty_mapping.get(transformation, \"unknown\")\n",
    "    \n",
    "    if transformation == \"original\":\n",
    "        group = \"original\"\n",
    "    else:\n",
    "        group = \"transformed\"\n",
    "     \n",
    "    csv_data.append({\n",
    "        \"file_path\": image_path,\n",
    "        \"label\": label,\n",
    "        \"transformation\": transformation,\n",
    "        \"difficulty\": difficulty,\n",
    "        \"group\": group\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(csv_data)\n",
    "df.to_csv(image_index_with_labels_csv, index=False)\n",
    "\n",
    "print(f\"CSV with additional labels at: {image_index_with_labels_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split dataset:\n",
      "    - Train:    3086 images (found at ../datasets/tattoos/dataset_split/train.csv)\n",
      "    - Validate: 662 images (found at ../datasets/tattoos/dataset_split/val.csv)\n",
      "    - Test:     662 images (found at ../datasets/tattoos/dataset_split/test.csv)\n"
     ]
    }
   ],
   "source": [
    "remove_folder(dataset_split_folder)\n",
    "\n",
    "train_size = 0.7\n",
    "val_size = 0.15\n",
    "test_size = 0.15\n",
    "\n",
    "data = pd.read_csv(image_index_with_labels_csv)\n",
    "data = data[data[\"label\"] != \"temp\"]\n",
    "# print(data[\"label\"].value_counts())\n",
    "\n",
    "train_data, temp_data = train_test_split(data, test_size=(1 - train_size), stratify=data[\"label\"], random_state=42)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=(test_size / (val_size + test_size)), stratify=temp_data[\"label\"], random_state=42)\n",
    "\n",
    "train_data.to_csv(train_csv, index=False)\n",
    "val_data.to_csv(val_csv, index=False)\n",
    "test_data.to_csv(test_csv, index=False)\n",
    "\n",
    "print(f\"Split dataset:\")\n",
    "print(f\"    - Train:    {len(train_data)} images (found at {train_csv})\")\n",
    "print(f\"    - Validate: {len(val_data)} images (found at {val_csv})\")\n",
    "print(f\"    - Test:     {len(test_data)} images (found at {test_csv})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load ResNet model\n",
    "\n",
    "Configure ResNet for characteristic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /Users/administrator/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
      "100%|██████████| 20.5M/20.5M [00:03<00:00, 6.61MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (1): AdaptiveAvgPool2d(output_size=1)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configurar dispositivo (GPU, MPS o CPU)\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Cargar modelo ResNet preentrenado\n",
    "model = efficientnet_b0(weights=EfficientNet_B0_Weights.IMAGENET1K_V1)\n",
    "# Quitar la última capa para obtener vectores de características\n",
    "model = nn.Sequential(*list(model.children())[:-1])\n",
    "model = model.to(device)\n",
    "model.eval()  # Configurar en modo evaluación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformaciones necesarias para ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Tamaño esperado por ResNet\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalización estándar\n",
    "])\n",
    "\n",
    "# Función para procesar una imagen y obtener su vector de características\n",
    "def extract_features(image_path, model, device):\n",
    "    image = Image.open(image_path).convert(\"RGB\")  # Asegurarse de que sea RGB\n",
    "    input_tensor = transform(image).unsqueeze(0).to(device)  # Transformar y agregar dimensión batch\n",
    "    with torch.no_grad():\n",
    "        features = model(input_tensor).squeeze()  # Pasar por el modelo y aplanar\n",
    "    return features.cpu().numpy()  # Convertir a numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ruta de la imagen a comparar\n",
    "query_image_path = f\"{images_path}/1_1_ar1.JPG\"\n",
    "\n",
    "# Extraer características de la imagen de consulta\n",
    "query_features = extract_features(query_image_path, model, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and match against original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen de consulta: ../datasets/tattoos/images/1_1_ar1.JPG\n",
      "Imágenes más similares:\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar1.JPG, Similitud: 1.0000\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar4.JPG, Similitud: 0.9997\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar3.JPG, Similitud: 0.9997\n",
      "Imagen: ../datasets/tattoos/images/1_1.JPG, Similitud: 0.9994\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar2.JPG, Similitud: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# Extraer características de todas las imágenes del dataset\n",
    "original_dataset_features = []\n",
    "original_image_paths = []\n",
    "for file_name in os.listdir(images_path):\n",
    "    if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(images_path, file_name)\n",
    "        features = extract_features(image_path, model, device)\n",
    "        original_dataset_features.append(features)\n",
    "        original_image_paths.append(image_path)\n",
    "\n",
    "# Convertir a numpy array para facilitar cálculos\n",
    "original_dataset_features = np.array(original_dataset_features)\n",
    "\n",
    "# Calcular similitudes (usando distancia coseno)\n",
    "similarities = cosine_similarity(query_features.reshape(1, -1), original_dataset_features)[0]\n",
    "\n",
    "# Ordenar resultados por similitud\n",
    "sorted_indices = np.argsort(similarities)[::-1]  # De mayor a menor\n",
    "top_k = 5  # Número de resultados más similares a mostrar\n",
    "\n",
    "print(f\"Imagen de consulta: {query_image_path}\")\n",
    "print(\"Imágenes más similares:\")\n",
    "for idx in sorted_indices[:top_k]:\n",
    "    print(f\"Imagen: {original_image_paths[idx]}, Similitud: {similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and match against resized dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen de consulta: ../datasets/tattoos/images/1_1_ar1.JPG\n",
      "Imágenes más similares:\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar1.JPG, Similitud: 1.0000\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar4.JPG, Similitud: 0.9997\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar3.JPG, Similitud: 0.9997\n",
      "Imagen: ../datasets/tattoos/images/1_1.JPG, Similitud: 0.9994\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar2.JPG, Similitud: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# Extraer características de todas las imágenes del dataset\n",
    "resized_dataset_features = []\n",
    "resized_image_paths = []\n",
    "for file_name in os.listdir(resized_images_folder):\n",
    "    if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(images_path, file_name)\n",
    "        features = extract_features(image_path, model, device)\n",
    "        resized_dataset_features.append(features)\n",
    "        resized_image_paths.append(image_path)\n",
    "\n",
    "# Convertir a numpy array para facilitar cálculos\n",
    "resized_dataset_features = np.array(resized_dataset_features)\n",
    "\n",
    "# Calcular similitudes (usando distancia coseno)\n",
    "similarities = cosine_similarity(query_features.reshape(1, -1), resized_dataset_features)[0]\n",
    "\n",
    "# Ordenar resultados por similitud\n",
    "sorted_indices = np.argsort(similarities)[::-1]  # De mayor a menor\n",
    "top_k = 5  # Número de resultados más similares a mostrar\n",
    "\n",
    "print(f\"Imagen de consulta: {query_image_path}\")\n",
    "print(\"Imágenes más similares:\")\n",
    "for idx in sorted_indices[:top_k]:\n",
    "    print(f\"Imagen: {resized_image_paths[idx]}, Similitud: {similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract and match against processed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imagen de consulta: ../datasets/tattoos/images/1_1_ar1.JPG\n",
      "Imágenes más similares:\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar1.JPG, Similitud: 1.0000\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar4.JPG, Similitud: 0.9997\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar3.JPG, Similitud: 0.9997\n",
      "Imagen: ../datasets/tattoos/images/1_1.JPG, Similitud: 0.9994\n",
      "Imagen: ../datasets/tattoos/images/1_1_ar2.JPG, Similitud: 0.9988\n"
     ]
    }
   ],
   "source": [
    "# Extraer características de todas las imágenes del dataset\n",
    "processed_dataset_features = []\n",
    "processed_image_paths = []\n",
    "for file_name in os.listdir(processed_images_folder):\n",
    "    if file_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "        image_path = os.path.join(images_path, file_name)\n",
    "        features = extract_features(image_path, model, device)\n",
    "        processed_dataset_features.append(features)\n",
    "        processed_image_paths.append(image_path)\n",
    "\n",
    "# Convertir a numpy array para facilitar cálculos\n",
    "processed_dataset_features = np.array(processed_dataset_features)\n",
    "\n",
    "# Calcular similitudes (usando distancia coseno)\n",
    "similarities = cosine_similarity(query_features.reshape(1, -1), processed_dataset_features)[0]\n",
    "\n",
    "# Ordenar resultados por similitud\n",
    "sorted_indices = np.argsort(similarities)[::-1]  # De mayor a menor\n",
    "top_k = 5  # Número de resultados más similares a mostrar\n",
    "\n",
    "print(f\"Imagen de consulta: {query_image_path}\")\n",
    "print(\"Imágenes más similares:\")\n",
    "for idx in sorted_indices[:top_k]:\n",
    "    print(f\"Imagen: {processed_image_paths[idx]}, Similitud: {similarities[idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Total Time\n",
    "\n",
    "This show the total time of execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total execution time: 4.0 minutes and 49.24 seconds\n"
     ]
    }
   ],
   "source": [
    "# Sets the total time of execution\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "\n",
    "# Calculate minutes and seconds\n",
    "minutes = execution_time // 60  # Integer division for whole minutes\n",
    "seconds = execution_time % 60   # Remainder for leftover seconds\n",
    "\n",
    "print(f\"Total execution time: {minutes} minutes and {seconds:.2f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "maestria-sandbox-M6nm_6C6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
